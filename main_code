# Import libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout

# Load the dataset (Replace 'data.csv' with your file path)
# The dataset should have a 'Date' and 'Value' columns or similar structure
df = pd.read_csv(r'C:\\Users\\tonge\\OneDrive\Desktop\\all report.csv', parse_dates=['Date'], index_col='Date')

# Plot the data
plt.figure(figsize=(10,6))
plt.plot(df['Value'])
plt.title('Time Series Data')
plt.xlabel('Date')
plt.ylabel('Value')
plt.show()

# Preprocessing the data
# Normalize the dataset using MinMaxScaler
scaler = MinMaxScaler(feature_range=(0, 1))
scaled_data = scaler.fit_transform(df['Value'].values.reshape(-1, 1))

# Create a dataset in the form of input (X) and output (Y)
def create_dataset(data, time_step=60):
    X, Y = [], []
    for i in range(len(data) - time_step - 1):
        X.append(data[i:(i + time_step), 0])
        Y.append(data[i + time_step, 0])
    return np.array(X), np.array(Y)

# Define time step (window size)
time_step = 60

# Split data into training (80%) and testing (20%) sets
train_size = int(len(scaled_data) * 0.8)
test_size = len(scaled_data) - train_size

train_data = scaled_data[0:train_size]
test_data = scaled_data[train_size:]

# Create training and testing datasets
X_train, y_train = create_dataset(train_data, time_step)
X_test, y_test = create_dataset(test_data, time_step)

# Reshape input data to be in the format [samples, time steps, features] for LSTM
X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)
X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)

# Build the LSTM model
model = Sequential()
model.add(LSTM(units=50, return_sequences=True, input_shape=(time_step, 1)))
model.add(Dropout(0.2))  # Prevent overfitting
model.add(LSTM(units=50, return_sequences=False))
model.add(Dropout(0.2))
model.add(Dense(units=25))
model.add(Dense(units=1))

# Compile the model
model.compile(optimizer='adam', loss='mean_squared_error')

# Train the model
history = model.fit(X_train, y_train, epochs=100, batch_size=64, validation_data=(X_test, y_test))

# Plot the training and validation loss
plt.figure(figsize=(10,6))
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Model Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()

# Predictions on the test set
predictions = model.predict(X_test)

# Reverse the scaling
predictions = scaler.inverse_transform(predictions)
y_test_scaled = scaler.inverse_transform(y_test.reshape(-1, 1))

# Plot the predicted vs actual values
plt.figure(figsize=(10,6))
plt.plot(df.index[len(df)-len(y_test):], y_test_scaled, label='Actual Values')
plt.plot(df.index[len(df)-len(y_test):], predictions, label='Predicted Values')
plt.title('Actual vs Predicted')
plt.xlabel('Date')
plt.ylabel('Value')
plt.legend()
plt.show()

# Model evaluation using Root Mean Squared Error (RMSE)
from sklearn.metrics import mean_squared_error
rmse = np.sqrt(mean_squared_error(y_test_scaled, predictions))
print(f'Root Mean Squared Error: {rmse}')

# Future Prediction
# Predict the next value based on the last `time_step` values of the test set
last_sequence = scaled_data[-time_step:]
last_sequence = last_sequence.reshape((1, time_step, 1))
future_prediction = model.predict(last_sequence)
future_prediction = scaler.inverse_transform(future_prediction)
print(f'Predicted Next Value: {future_prediction[0][0]}')
